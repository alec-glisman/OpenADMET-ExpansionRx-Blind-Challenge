{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b72a359",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7f1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c53c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "import useful_rdkit_utils as uru\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.DataStructs import BulkTanimotoSimilarity\n",
    "\n",
    "from admet.model.lgbm_wrapper import LGBMMorganCountWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5648f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb53cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4beeca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 20:17:02,831 - __main__ - INFO - Imports successful.\n"
     ]
    }
   ],
   "source": [
    "# setup logging\n",
    "level = logging.DEBUG\n",
    "logger = logging.getLogger(__name__)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(level)\n",
    "\n",
    "logger.info(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9f1d1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6ca05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 20:17:02,858 - __main__ - INFO - Output directory set to /media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/OpenADMET-ExpansionRx-Blind-Challenge/assets/dataset/splits\n",
      "2025-11-15 20:17:02,859 - __main__ - INFO - Input data directory found at /media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/OpenADMET-ExpansionRx-Blind-Challenge/assets/dataset/eda/data/set\n",
      "2025-11-15 20:17:02,859 - __main__ - INFO - Dataset name: cleaned_combined_datasets_low_quality_summary_table.csv\n",
      "2025-11-15 20:17:02,859 - __main__ - INFO - Dataset name: cleaned_combined_datasets_medium_quality_summary_table.csv\n",
      "2025-11-15 20:17:02,860 - __main__ - INFO - Dataset name: cleaned_combined_datasets_medium_quality.csv\n",
      "2025-11-15 20:17:02,860 - __main__ - INFO - Dataset name: cleaned_combined_datasets_low_medium_high_quality.csv\n",
      "2025-11-15 20:17:02,860 - __main__ - INFO - Dataset name: cleaned_combined_datasets_high_quality.csv\n",
      "2025-11-15 20:17:02,860 - __main__ - INFO - Dataset name: cleaned_combined_datasets_high_quality_summary_table.csv\n",
      "2025-11-15 20:17:02,860 - __main__ - INFO - Dataset name: cleaned_combined_datasets_low_quality.csv\n",
      "2025-11-15 20:17:02,860 - __main__ - INFO - Dataset name: cleaned_combined_datasets_medium_high_quality.csv\n"
     ]
    }
   ],
   "source": [
    "# Data input and output directories\n",
    "base_data_dir = Path().cwd().parents[0] / \"assets/dataset/eda/data/set\"\n",
    "output_dir = base_data_dir.parents[2] / \"splits\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not base_data_dir.exists():\n",
    "    raise FileNotFoundError(f\"Data directory not found at {base_data_dir}\")\n",
    "\n",
    "logger.info(f\"Output directory set to {output_dir}\")\n",
    "logger.info(f\"Input data directory found at {base_data_dir}\")\n",
    "for dataset_dir in base_data_dir.iterdir():\n",
    "    logger.info(f\"Dataset name: {dataset_dir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad02795",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgen = rdFingerprintGenerator.GetMorganGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a1daed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 20:20:36,071 - __main__ - INFO - Dataset: high, shape: (5326, 12)\n",
      "2025-11-15 20:20:36,072 - __main__ - INFO - Columns: ['Molecule Name', 'SMILES', 'Dataset', 'LogD', 'KSOL', 'HLM CLint', 'MLM CLint', 'Caco-2 Permeability Papp A>B', 'Caco-2 Permeability Efflux', 'MPPB', 'MBPB', 'MGMB']\n",
      "2025-11-15 20:20:36,080 - __main__ - INFO - Unique Dataset Constituents: ['expansionrx']\n",
      "2025-11-15 20:20:36,081 - __main__ - INFO - Dataset: medium, shape: (94708, 12)\n",
      "2025-11-15 20:20:36,081 - __main__ - INFO - Columns: ['Molecule Name', 'SMILES', 'Dataset', 'LogD', 'KSOL', 'HLM CLint', 'MLM CLint', 'Caco-2 Permeability Papp A>B', 'Caco-2 Permeability Efflux', 'MPPB', 'MBPB', 'MGMB']\n",
      "2025-11-15 20:20:36,083 - __main__ - INFO - Unique Dataset Constituents: ['expansionrx' 'kermt_public']\n",
      "2025-11-15 20:20:36,084 - __main__ - INFO - Dataset: low, shape: (116527, 12)\n",
      "2025-11-15 20:20:36,084 - __main__ - INFO - Columns: ['Molecule Name', 'SMILES', 'Dataset', 'LogD', 'KSOL', 'HLM CLint', 'MLM CLint', 'Caco-2 Permeability Efflux', 'MPPB', 'Caco-2 Permeability Papp A>B', 'MBPB', 'MGMB']\n",
      "2025-11-15 20:20:36,087 - __main__ - INFO - Unique Dataset Constituents: ['kermt_biogen' 'pharmabench' 'expansionrx' 'kermt_public']\n"
     ]
    }
   ],
   "source": [
    "# Load input datasets\n",
    "datasets = {\n",
    "    \"high\": pd.read_csv(base_data_dir / \"cleaned_combined_datasets_high_quality.csv\"),\n",
    "    \"medium\": pd.read_csv(\n",
    "        base_data_dir / \"cleaned_combined_datasets_medium_high_quality.csv\", low_memory=False\n",
    "    ),\n",
    "    \"low\": pd.read_csv(\n",
    "        base_data_dir / \"cleaned_combined_datasets_low_medium_high_quality.csv\", low_memory=False\n",
    "    ),\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    logger.info(f\"Dataset: {name}, shape: {df.shape}\")\n",
    "    logger.info(f\"Columns: {df.columns.tolist()}\")\n",
    "    logger.info(f\"Unique Dataset Constituents: {df['Dataset'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbab8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "n_splits = 5\n",
    "\n",
    "split_list = [\n",
    "    \"random_cluster\",\n",
    "    \"scaffold_cluster\",\n",
    "    \"butina_cluster\",\n",
    "    # \"umap_cluster\",\n",
    "]\n",
    "split_dict = {\n",
    "    \"random_cluster\": uru.get_random_clusters,\n",
    "    \"scaffold_cluster\": uru.get_bemis_murcko_clusters,\n",
    "    \"butina_cluster\": uru.get_butina_clusters,\n",
    "    # \"umap_cluster\": uru.get_umap_clusters,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: update the clusters and splitting to be stratified based on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cec710",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for split in split_list:\n",
    "    for i in tqdm(range(0, n_folds), desc=split):\n",
    "        cluster_list = split_dict[split](size_df.SMILES)\n",
    "        group_kfold_shuffle = uru.GroupKFoldShuffle(n_splits=n_splits, shuffle=True)\n",
    "        for train, test in group_kfold_shuffle.split(np.stack(size_df.fp), size_df.logS, cluster_list):\n",
    "            result_list.append([split, len(test)])\n",
    "result_df = pd.DataFrame(result_list, columns=[\"split\", \"num_test\"])\n",
    "result_df.to_csv(output_dir / \"dataset_split_sizes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"split\", y=\"num_test\", data=result_df)\n",
    "ax.set_xlabel(\"Dataset Splitting Strategy\")\n",
    "ax.set_ylabel(\"Test Set Size\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenADMET-ExpansionRx-Blind-Challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
