{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903e0575",
   "metadata": {},
   "source": [
    "# Data Cleaning, Harmonization, and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6866e78",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea1556",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998925a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'colorcet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional, Sequence, Tuple, Iterable, List\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# third-party libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcolorcet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcc\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'colorcet'"
     ]
    }
   ],
   "source": [
    "# standard library\n",
    "from concurrent import futures\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Sequence, Tuple, Iterable, List\n",
    "\n",
    "# third-party libraries\n",
    "import colorcet as cc\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import SaltRemover, Descriptors, rdMolDescriptors\n",
    "from scipy import stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# local libraries\n",
    "from admet.data.chem import (\n",
    "    parallel_canonicalize_smiles,\n",
    "    compute_molecular_properties,\n",
    ")\n",
    "from admet.data.constants import (\n",
    "    TRANSFORMATIONS,\n",
    "    COLS_WITH_UNITS,\n",
    ")\n",
    "from admet.visualize.plots import (\n",
    "    plot_numeric_distributions,\n",
    "    plot_correlation_matrix,\n",
    "    plot_property_distributions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa8c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f596fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "level = logging.DEBUG\n",
    "logger = logging.getLogger(__name__)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(level)\n",
    "\n",
    "logger.info(\"Imports successful.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b363f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f66734",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a417eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project data root directory\n",
    "base_data_dir = Path().cwd().parents[0] / \"assets/dataset/raw\"\n",
    "\n",
    "if not base_data_dir.exists():\n",
    "    raise FileNotFoundError(f\"Data directory not found at {base_data_dir}\")\n",
    "\n",
    "logger.info(f\"Data directory found at {base_data_dir}\")\n",
    "for dataset_dir in base_data_dir.iterdir():\n",
    "    logger.info(f\"Dataset name: {dataset_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da2104",
   "metadata": {},
   "source": [
    "### Challenge Data: ExpansionRX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64363c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = base_data_dir / \"ExpansionRX/full/expansion_data_train.csv\"\n",
    "df_expansionrx = pd.read_csv(data_path)\n",
    "\n",
    "# rename cols to have units\n",
    "df_expansionrx.rename(\n",
    "    columns={k: f\"{k} {v}\" for k, v in COLS_WITH_UNITS.items() if k in df_expansionrx.columns},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# drop rows with invalid SMILES\n",
    "df_expansionrx[\"SMILES\"] = parallel_canonicalize_smiles(\n",
    "    df_expansionrx[\"SMILES\"].tolist(),\n",
    "    isomeric=True,\n",
    ")\n",
    "n_none_smiles = df_expansionrx[\"SMILES\"].isnull().sum()\n",
    "if n_none_smiles > 0:\n",
    "    logger.warning(f\"Dropping {n_none_smiles} rows with invalid SMILES\")\n",
    "    df_expansionrx.dropna(subset=[\"SMILES\"], inplace=True)\n",
    "    df_expansionrx.reset_index(drop=True, inplace=True)\n",
    "\n",
    "logger.info(f\"Dataframe shape: {df_expansionrx.shape}\")\n",
    "logger.info(f\"Dataframe columns: {df_expansionrx.columns.tolist()}\")\n",
    "\n",
    "# is the teaser data a subset of the full data?\n",
    "merged_df = df_expansionrx.merge(\n",
    "    df_expansionrx,\n",
    "    on=[\"SMILES\"] + [col for col in df_expansionrx.columns if col != \"SMILES\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "if merged_df.shape[0] == df_expansionrx.shape[0]:\n",
    "    logger.info(\"The teaser data is a subset of the full data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expansionrx.sort_values(\"Molecule Name (None)\", inplace=True)\n",
    "df_expansionrx.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_expansionrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33721466",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[\"expansionrx\"] = df_expansionrx.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_expansionrx.copy()\n",
    "output_dir = data_path.parents[1] / \"figures\"\n",
    "fname = \"expansionrx\"\n",
    "\n",
    "df_props = compute_molecular_properties(df[\"SMILES\"])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig, ax = plot_numeric_distributions(\n",
    "    df,\n",
    "    n_cols=3,\n",
    "    title=\"ExpansionRx Teaser Property Distributions\",\n",
    "    save_path=output_dir / f\"{fname}_numeric_distributions.png\",\n",
    ")\n",
    "fig, ax = plot_property_distributions(\n",
    "    df_props,\n",
    "    save_path=output_dir / f\"{fname}_molecular_property_distributions.png\",\n",
    ")\n",
    "fig, ax = plot_correlation_matrix(\n",
    "    df,\n",
    "    save_path=output_dir / f\"{fname}_numeric_correlation_matrix.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50488cda",
   "metadata": {},
   "source": [
    "### KERMT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a88b73",
   "metadata": {},
   "source": [
    "#### Public"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e59a97",
   "metadata": {},
   "source": [
    "Key dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea175a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_biogen = [\n",
    "    \"KERMT/export_public_cluster_split/all_test_cluster_morgan.csv\",\n",
    "    \"KERMT/export_public_cluster_split/all_train_fold_0_cluster_morgan.csv\",\n",
    "    \"KERMT/export_public_cluster_split/all_val_fold_0_cluster_morgan.csv\",\n",
    "]\n",
    "\n",
    "# map from KERMT data to ExpansionRX data on SMILES\n",
    "map_cols_kermt_to_expansionrx = [\n",
    "    {\n",
    "        \"input_col\": \"LogD_pH_7.4\",\n",
    "        \"output_col\": \"LogD (None)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"None\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"kinetic_logSaq\",  # log(M)\n",
    "        \"output_col\": \"KSOL (uM)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x+6)\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"CL_microsome_human\",  # log(mL/min/kg)\n",
    "        \"output_col\": \"HLM CLint (mL/min/kg)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x)\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"CL_microsome_mouse\",  # log(mL/min/kg)\n",
    "        \"output_col\": \"MLM CLint (mL/min/kg)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x)\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"Papp_Caco2\",  # log(10^-6 cm/sec)\n",
    "        \"output_col\": \"Caco-2 Permeability Papp A>B (10^-6 cm/s)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x)\"],\n",
    "    },\n",
    "    {\n",
    "        # REVIEW: low confidence mapping\n",
    "        \"input_col\": \"Pgp_human\",  # log(None)\n",
    "        \"output_col\": \"Caco-2 Permeability Efflux (None)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x)\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e35f4",
   "metadata": {},
   "source": [
    "Load and concatenate public KERMT files. Drop duplicates and bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kermt_public = pd.DataFrame()\n",
    "for f in files_biogen:\n",
    "    df = pd.read_csv(base_data_dir / f)\n",
    "    df[\"file\"] = f\n",
    "    df_kermt_public = pd.concat([df_kermt_public, df], ignore_index=True)\n",
    "\n",
    "# rename smiles --> SMILES\n",
    "df_kermt_public.rename(columns={\"smiles\": \"SMILES\"}, inplace=True)\n",
    "\n",
    "# drop rows with invalid SMILES\n",
    "df_kermt_public[\"SMILES\"] = parallel_canonicalize_smiles(\n",
    "    df_kermt_public[\"SMILES\"].tolist(),\n",
    "    isomeric=True,\n",
    ")\n",
    "n_none_smiles = df_kermt_public[\"SMILES\"].isnull().sum()\n",
    "if n_none_smiles > 0:\n",
    "    logger.warning(f\"Dropping {n_none_smiles} rows with invalid SMILES\")\n",
    "    df_kermt_public.dropna(subset=[\"SMILES\"], inplace=True)\n",
    "    df_kermt_public.reset_index(drop=True, inplace=True)\n",
    "\n",
    "logger.info(f\"KERMT Public Dataframe shape: {df_kermt_public.shape}\")\n",
    "logger.info(f\"KERMT Public Dataframe columns: {df_kermt_public.columns.tolist()}\")\n",
    "\n",
    "# print finite number of entries for each column\n",
    "for col in df_kermt_public.columns:\n",
    "    if not pd.api.types.is_numeric_dtype(df_kermt_public[col]):\n",
    "        continue\n",
    "    n_finite = np.isfinite(df_kermt_public[col]).sum()\n",
    "    logger.info(f\"Column '{col}' has {n_finite} finite entries out of {len(df_kermt_public)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f3764",
   "metadata": {},
   "source": [
    "Transform dataset column names to be compatible with ExpansionRX dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328325e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kermt_public_admet_cleaned = df_kermt_public[[\"SMILES\"]]\n",
    "for mapping in map_cols_kermt_to_expansionrx:\n",
    "    input_col = mapping[\"input_col\"]\n",
    "    output_col = mapping[\"output_col\"]\n",
    "    transform = mapping[\"transform\"]\n",
    "\n",
    "    df_input = df_kermt_public[[\"SMILES\", input_col]].copy()\n",
    "    df_input[output_col] = df_input[input_col].apply(transform).copy()\n",
    "    df_input.drop(columns=[input_col], inplace=True)\n",
    "\n",
    "    df_kermt_public_admet_cleaned = pd.merge(df_kermt_public_admet_cleaned, df_input, on=\"SMILES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059480b1",
   "metadata": {},
   "source": [
    "Curate dataset to include relevant dynamic ranges for main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit KSol to < 250\n",
    "idx_infinite_ksol = df_kermt_public_admet_cleaned[\"KSOL (uM)\"].isnull()\n",
    "idx_too_large = df_kermt_public_admet_cleaned[\"KSOL (uM)\"] > 250.0\n",
    "idx_remove = ~idx_infinite_ksol & idx_too_large\n",
    "df_kermt_public_admet_cleaned = df_kermt_public_admet_cleaned[~idx_remove].reset_index(drop=True)\n",
    "\n",
    "# limit Caco-2 Permeability Papp A>B to < 100\n",
    "idx_infinite_caco2 = df_kermt_public_admet_cleaned[\"Caco-2 Permeability Papp A>B (10^-6 cm/s)\"].isnull()\n",
    "idx_too_large_caco2 = df_kermt_public_admet_cleaned[\"Caco-2 Permeability Papp A>B (10^-6 cm/s)\"] > 100.0\n",
    "idx_remove_caco2 = ~idx_infinite_caco2 & idx_too_large_caco2\n",
    "df_kermt_public_admet_cleaned = df_kermt_public_admet_cleaned[~idx_remove_caco2].reset_index(drop=True)\n",
    "\n",
    "# limit Caco-2 Permeability Efflux to < 100\n",
    "idx_infinite_efflux = df_kermt_public_admet_cleaned[\"Caco-2 Permeability Efflux (None)\"].isnull()\n",
    "idx_too_large_efflux = df_kermt_public_admet_cleaned[\"Caco-2 Permeability Efflux (None)\"] > 100.0\n",
    "idx_remove_efflux = ~idx_infinite_efflux & idx_too_large_efflux\n",
    "df_kermt_public_admet_cleaned = df_kermt_public_admet_cleaned[~idx_remove_efflux].reset_index(drop=True)\n",
    "\n",
    "# drop rows with all NaN values across ADMET columns\n",
    "admet_cols = [mapping[\"output_col\"] for mapping in map_cols_kermt_to_expansionrx]\n",
    "df_kermt_public_admet_cleaned.dropna(subset=admet_cols, how=\"all\", inplace=True)\n",
    "df_kermt_public_admet_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "logger.info(f\"Merged KERMT-ExpansionRX Dataframe shape: {df_kermt_public_admet_cleaned.shape}\")\n",
    "logger.info(f\"Merged KERMT-ExpansionRX Dataframe columns: {df_kermt_public_admet_cleaned.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51212db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for repeated SMILES\n",
    "n_total = len(df_kermt_public_admet_cleaned)\n",
    "n_unique = df_kermt_public_admet_cleaned[\"SMILES\"].nunique()\n",
    "n_duplicates = n_total - n_unique\n",
    "if n_duplicates > 0:\n",
    "    logger.warning(f\"Found {n_duplicates} duplicate SMILES in merged KERMT-ExpansionRX dataframe\")\n",
    "    # average (skip NaNs) over duplicates\n",
    "    df_kermt_public_admet_cleaned = df_kermt_public_admet_cleaned.groupby(\"SMILES\", as_index=False).mean()\n",
    "    logger.info(f\"Dataframe shape after averaging duplicates: {df_kermt_public_admet_cleaned.shape}\")\n",
    "\n",
    "# check for overlap with ExpansionRx teaser dataset\n",
    "smiles_teaser = set(df_expansionrx[\"SMILES\"].tolist())\n",
    "smiles_kermt_expansionrx = set(df_kermt_public_admet_cleaned[\"SMILES\"].tolist())\n",
    "overlap_smiles = smiles_teaser.intersection(smiles_kermt_expansionrx)\n",
    "n_overlap = len(overlap_smiles)\n",
    "if n_overlap > 0:\n",
    "    logger.warning(f\"Found {n_overlap} overlapping SMILES between ExpansionRx teaser and KERMT-ExpansionRX datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print num non-nan entries for each column\n",
    "for col in df_kermt_public_admet_cleaned.columns:\n",
    "    if col == \"SMILES\":\n",
    "        continue\n",
    "    n_non_nan = df_kermt_public_admet_cleaned[col].notna().sum()\n",
    "    logger.info(f\"Column '{col}' has {n_non_nan} non-NaN entries out of {len(df_kermt_public_admet_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf0132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[\"kermt_public\"] = df_kermt_public_admet_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ec9fc",
   "metadata": {},
   "source": [
    "Visualize distributions of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431dd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_kermt_public_admet_cleaned.copy()\n",
    "fname = \"kermt_public_admet_cleaned\"\n",
    "\n",
    "output_dir = data_path.parents[1] / \"figures\"\n",
    "df_props = compute_molecular_properties(df[\"SMILES\"])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig, ax = plot_numeric_distributions(\n",
    "    df,\n",
    "    n_cols=3,\n",
    "    title=\"KERMT Public ADMET Cleaned Property Distributions\",\n",
    "    save_path=output_dir / f\"{fname}_numeric_distributions.png\",\n",
    ")\n",
    "fig, ax = plot_property_distributions(\n",
    "    df_props,\n",
    "    save_path=output_dir / f\"{fname}_molecular_property_distributions.png\",\n",
    ")\n",
    "fig, ax = plot_correlation_matrix(\n",
    "    df,\n",
    "    save_path=output_dir / f\"{fname}_numeric_correlation_matrix.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e3eba",
   "metadata": {},
   "source": [
    "#### Biogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_biogen = [\n",
    "    \"KERMT/export_biogen_cluster_split/all_test_cluster_morgan.csv\",\n",
    "    \"KERMT/export_biogen_cluster_split/all_train_fold_0_cluster_morgan.csv\",\n",
    "    \"KERMT/export_biogen_cluster_split/all_val_fold_0_cluster_morgan.csv\",\n",
    "]\n",
    "\n",
    "map_cols_biogen_to_expansionrx = [\n",
    "    {\n",
    "        \"input_col\": \"SOLY_6.8\", # FIXME: This is not pH 7\n",
    "        \"output_col\": \"KSOL (uM)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"ug/mL to uM\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"MDR1-MDCK_ER\", # FIXME: MDCK not Caco-2\n",
    "        \"output_col\": \"Caco-2 Permeability Efflux (None)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"None\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"HLM_CLint\",\n",
    "        \"output_col\": \"HLM CLint (mL/min/kg)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x)\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and concatenate biogen files\n",
    "df_kermt_biogen = [pd.read_csv(base_data_dir / file) for file in files_biogen]\n",
    "df_kermt_biogen = pd.concat(df_kermt_biogen, ignore_index=True)\n",
    "logger.info(f\"KERMT Biogen Dataframe shape: {df_kermt_biogen.shape}\")\n",
    "logger.info(f\"KERMT Biogen Dataframe columns: {df_kermt_biogen.columns.tolist()}\")\n",
    "\n",
    "# rename smiles --> SMILES\n",
    "df_kermt_biogen.rename(columns={\"smiles\": \"SMILES\"}, inplace=True)\n",
    "\n",
    "# drop rows with invalid SMILES\n",
    "df_kermt_biogen[\"SMILES\"] = parallel_canonicalize_smiles(\n",
    "    df_kermt_biogen[\"SMILES\"].tolist(),\n",
    "    isomeric=True,\n",
    ")\n",
    "df_kermt_biogen[\"MW\"] = df_kermt_biogen[\"SMILES\"].apply(lambda smi: Descriptors.MolWt(Chem.MolFromSmiles(smi)) if smi is not None else np.nan)\n",
    "\n",
    "n_none_smiles = df_kermt_biogen[\"SMILES\"].isnull().sum()\n",
    "if n_none_smiles > 0:\n",
    "    logger.warning(f\"Dropping {n_none_smiles} rows with invalid SMILES\")\n",
    "    df_kermt_biogen.dropna(subset=[\"SMILES\"], inplace=True)\n",
    "    df_kermt_biogen.reset_index(drop=True, inplace=True)\n",
    "logger.info(f\"KERMT Biogen Dataframe shape after cleaning: {df_kermt_biogen.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to ExpansionRX columns\n",
    "df_kermt_biogen_admet_cleaned = df_kermt_biogen[[\"SMILES\"]]\n",
    "for mapping in map_cols_biogen_to_expansionrx:\n",
    "    input_col = mapping[\"input_col\"]\n",
    "    output_col = mapping[\"output_col\"]\n",
    "    transform = mapping[\"transform\"]\n",
    "\n",
    "    df_input = df_kermt_biogen[[\"SMILES\", input_col]].copy()\n",
    "    if input_col == \"SOLY_6.8\":\n",
    "        # need MW for conversion\n",
    "        df_input = pd.merge(\n",
    "            df_input,\n",
    "            df_kermt_biogen[[\"SMILES\", \"MW\"]],\n",
    "            on=\"SMILES\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        df_input[output_col] = df_input.apply(\n",
    "            lambda row: transform(row[input_col], row[\"MW\"]),\n",
    "            axis=1,\n",
    "        )\n",
    "        df_input.drop(columns=[\"MW\"], inplace=True)\n",
    "    else:\n",
    "        df_input[output_col] = df_input[input_col].apply(transform).copy()\n",
    "        \n",
    "    logger.info(f\"Transformed column '{input_col}' to '{output_col}' with {len(df_input)} entries.\")\n",
    "    df_input.drop(columns=[input_col], inplace=True)\n",
    "\n",
    "    df_kermt_biogen_admet_cleaned = pd.merge(df_kermt_biogen_admet_cleaned, df_input, on=\"SMILES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print num non-nan entries for each column\n",
    "for col in df_kermt_biogen_admet_cleaned.columns:\n",
    "    if col == \"SMILES\":\n",
    "        continue\n",
    "    n_non_nan = df_kermt_biogen_admet_cleaned[col].notna().sum()\n",
    "    logger.info(f\"Column '{col}' has {n_non_nan} non-NaN entries out of {len(df_kermt_biogen_admet_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "logger.info(f\"KERMT Biogen-ExpansionRX Dataframe shape: {df_kermt_biogen_admet_cleaned.shape}\")\n",
    "cleaned_data[\"kermt_biogen\"] = df_kermt_biogen_admet_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219913d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_kermt_biogen_admet_cleaned.copy()\n",
    "output_dir = data_path.parents[1] / \"figures\"\n",
    "fname = \"kermt_biogen_admet_cleaned\"\n",
    "\n",
    "df_props = compute_molecular_properties(df[\"SMILES\"])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig, ax = plot_numeric_distributions(\n",
    "    df,\n",
    "    n_cols=3,\n",
    "    title=\"KERMT Biogen ADMET Cleaned Property Distributions\",\n",
    "    save_path=output_dir / f\"{fname}_numeric_distributions.png\",\n",
    ")\n",
    "fig, ax = plot_property_distributions(\n",
    "    df_props,\n",
    "    save_path=output_dir / f\"{fname}_molecular_property_distributions.png\",\n",
    ")\n",
    "fig, ax = plot_correlation_matrix(\n",
    "    df,\n",
    "    save_path=output_dir / f\"{fname}_numeric_correlation_matrix.png\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff70a3",
   "metadata": {},
   "source": [
    "### PharmaBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pharmabench = [\n",
    "    \"KERMT/export_biogen_cluster_split/all_test_cluster_morgan.csv\",\n",
    "    \"KERMT/export_biogen_cluster_split/all_train_fold_0_cluster_morgan.csv\",\n",
    "    \"KERMT/export_biogen_cluster_split/all_val_fold_0_cluster_morgan.csv\",\n",
    "]\n",
    "\n",
    "map_cols_pharmabench_to_expansionrx = [\n",
    "    {\n",
    "        \"input_col\": \"SOLY_6.8\",  # FIXME: This is not pH 7\n",
    "        \"output_col\": \"KSOL (uM)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"ug/mL to uM\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"MDR1-MDCK_ER\",  # FIXME: MDCK not Caco-2\n",
    "        \"output_col\": \"Caco-2 Permeability Efflux (None)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"None\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_col\": \"HLM_CLint\", # log10(mL/min/g)\n",
    "        \"output_col\": \"HLM CLint (mL/min/kg)\",\n",
    "        \"transform\": TRANSFORMATIONS[\"10^(x)\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b449048",
   "metadata": {},
   "source": [
    "### Admetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf739707",
   "metadata": {},
   "source": [
    "### TDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db65c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff871e",
   "metadata": {},
   "source": [
    "### NCATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64945696",
   "metadata": {},
   "source": [
    "### ChEMBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4713b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement loading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e48472",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fe3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all cleaned datasets as a single dataframe with column for dataset name\n",
    "df_out = pd.DataFrame()\n",
    "for name, df in cleaned_data.items():\n",
    "    logger.info(f\"Adding cleaned dataset '{name}' with shape {df.shape} to combined dataframe\")\n",
    "    df_temp = df.copy()\n",
    "    df_temp[\"dataset\"] = name\n",
    "    df_out = pd.concat([df_out, df_temp], axis=0)\n",
    "logger.info(f\"Combined cleaned dataframe shape: {df_out.shape}\")\n",
    "df_out.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# limit datasets to physically reasonable ranges\n",
    "df_props = compute_molecular_properties(df_out[\"SMILES\"])\n",
    "idx_drop = df_props[\"MW\"] > 1000.0\n",
    "idx_drop |= df_props[\"LogP\"] < -5.0\n",
    "idx_drop |= df_props[\"LogP\"] > 10.0\n",
    "idx_drop |= df_props[\"TPSA\"] > 300.0\n",
    "idx_drop |= df_props[\"HBA\"] > 20\n",
    "idx_drop |= df_props[\"HBD\"] > 10\n",
    "idx_drop |= df_props[\"RotBonds\"] > 20\n",
    "idx_drop |= df_props[\"NumRings\"] > 10\n",
    "# remove any idx_drop that are in the ExpansionRx teaser dataset\n",
    "idx_teaser = df_out[\"dataset\"] == \"expansionrx\"\n",
    "idx_drop = idx_drop & ~idx_teaser\n",
    "# drop entries\n",
    "n_dropped = idx_drop.sum()\n",
    "if n_dropped > 0:\n",
    "    logger.warning(f\"Dropping {n_dropped} entries from combined dataset due to unreasonable molecular properties\")\n",
    "    df_out = df_out.loc[~idx_drop].copy()\n",
    "    \n",
    "for name in cleaned_data.keys():\n",
    "    df_subset = df_out[df_out[\"dataset\"] == name]\n",
    "\n",
    "    # check for repeated SMILES\n",
    "    n_total = len(df_subset)\n",
    "    n_unique = df_subset[\"SMILES\"].nunique()\n",
    "    n_duplicates = n_total - n_unique\n",
    "    if n_duplicates > 0:\n",
    "        logger.warning(f\"Found {n_duplicates} duplicate SMILES in combined dataset for dataset '{name}'\")\n",
    "        # average (skip NaNs) over duplicates\n",
    "        df_subset = df_subset.groupby(\"SMILES\", as_index=False).mean()\n",
    "        # update in main dataframe\n",
    "        df_out = pd.concat(\n",
    "            [df_out[df_out[\"dataset\"] != name], df_subset],\n",
    "            axis=0,\n",
    "        )\n",
    "        logger.info(f\"Dataframe shape after averaging duplicates for dataset '{name}': {df_out.shape}\")\n",
    "        \n",
    "        # look for rows where all ADMET values are NaN\n",
    "        admet_cols = [col for col in df_subset.columns if col not in [\"SMILES\", \"dataset\"]]\n",
    "        n_before = len(df_out)\n",
    "        df_out = df_out.dropna(subset=admet_cols, how=\"all\")\n",
    "        n_after = len(df_out)\n",
    "        n_dropped = n_before - n_after\n",
    "        if n_dropped > 0:\n",
    "            logger.warning(f\"Dropped {n_dropped} rows with all NaN ADMET values for dataset '{name}' after averaging duplicates\")\n",
    "            df_out = df_out[df_out[\"dataset\"] != name]\n",
    "            df_out = pd.concat([df_out, df_subset], axis=0)\n",
    "\n",
    "# look at overlap between datasets\n",
    "dataset_names = list(cleaned_data.keys())\n",
    "for i in range(len(dataset_names)):\n",
    "    name_i = dataset_names[i]\n",
    "    smiles_i = set(df_out[df_out[\"dataset\"] == name_i][\"SMILES\"].tolist())\n",
    "    for j in range(i + 1, len(dataset_names)):\n",
    "        name_j = dataset_names[j]\n",
    "        smiles_j = set(df_out[df_out[\"dataset\"] == name_j][\"SMILES\"].tolist())\n",
    "        overlap_smiles = smiles_i.intersection(smiles_j)\n",
    "        n_overlap = len(overlap_smiles)\n",
    "        if n_overlap > 0:\n",
    "            logger.warning(f\"Found {n_overlap} overlapping SMILES between datasets '{name_i}' and '{name_j}'\")\n",
    "            \n",
    "# for any repeated SMILES across datasets, keep only the first occurrence, prioritizing\n",
    "# ExpansionRx teaser > KERMT Public > KERMT Biogen > Pharmabench\n",
    "df_out.sort_values(by=\"dataset\", inplace=True)\n",
    "df_out.drop_duplicates(subset=[\"SMILES\"], keep=\"first\", inplace=True) \n",
    "\n",
    "# save final combined cleaned dataset\n",
    "df_out.reset_index(drop=True, inplace=True)\n",
    "output_path = base_data_dir.parent / \"cleaned_combined_datasets.csv\"\n",
    "df_out.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of dataset counts\n",
    "dataset_counts = df_out[\"dataset\"].value_counts()\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    x=dataset_counts.index,\n",
    "    y=dataset_counts.values,\n",
    "    ax=ax,\n",
    "    palette=\"viridis\",\n",
    "    hue=dataset_counts.index,\n",
    "    dodge=False,\n",
    ")\n",
    "ax.set_xlabel(\"Dataset\", fontsize=14)\n",
    "ax.set_ylabel(\"Count\", fontsize=14)\n",
    "ax.set_title(\"Distribution of Dataset Counts\", fontsize=18)\n",
    "ax.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\n",
    "ax.set_yscale(\"log\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523cb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of targets colored by dataset\n",
    "target_cols = [col for col in df_out.columns if col != \"SMILES\" and col != \"dataset\"]\n",
    "\n",
    "colormap = cc.glasbey  # categorical colormap\n",
    "dataset_to_color = {name: colormap[i] for i, name in enumerate(df_out[\"dataset\"].unique())}\n",
    "\n",
    "for target_col in target_cols:\n",
    "    if not pd.api.types.is_numeric_dtype(df_out[target_col]):\n",
    "        continue\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    logger.info(f\"Plotting distribution for target column '{target_col}'\")\n",
    "    for dataset_name, group in df_out.groupby(\"dataset\"):\n",
    "        sns.kdeplot(\n",
    "            group[target_col].dropna(),\n",
    "            ax=ax,\n",
    "            label=dataset_name,\n",
    "            fill=True,\n",
    "            alpha=0.5,\n",
    "            color=dataset_to_color[dataset_name],\n",
    "        )\n",
    "    ax.set_xlabel(target_col, fontsize=14)\n",
    "    ax.set_ylabel(\"Density\", fontsize=14)\n",
    "    ax.set_title(f\"Distribution of {target_col} by Dataset\", fontsize=18)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\n",
    "    ax.legend(title=\"Dataset\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    fig.savefig(\n",
    "        output_dir / f\"combined_{target_col.replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_to_')}_distribution.png\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of molecular properties colored by dataset\n",
    "df_props = compute_molecular_properties(df_out[\"SMILES\"])\n",
    "df_props[\"dataset\"] = df_out[\"dataset\"]\n",
    "for prop_col in df_props.columns:\n",
    "    if prop_col == \"SMILES\" or prop_col == \"dataset\":\n",
    "        continue\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    logger.info(f\"Plotting distribution for molecular property '{prop_col}'\")\n",
    "    for dataset_name, group in df_props.groupby(\"dataset\"):\n",
    "        sns.kdeplot(\n",
    "            group[prop_col].dropna(),\n",
    "            ax=ax,\n",
    "            label=dataset_name,\n",
    "            fill=True,\n",
    "            alpha=0.5,\n",
    "            color=dataset_to_color[dataset_name],\n",
    "        )\n",
    "    ax.set_xlabel(prop_col, fontsize=14)\n",
    "    ax.set_ylabel(\"Density\", fontsize=14)\n",
    "    ax.set_title(f\"Distribution of {prop_col} by Dataset\", fontsize=18)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\n",
    "    ax.legend(title=\"Dataset\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    fig.savefig(\n",
    "        output_dir / f\"combined_{prop_col.replace(' ', '_').replace('(', '').replace(')', '')}_distribution.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfp.fingerprints import ECFPFingerprint\n",
    "from skfp.preprocessing import MolFromSmilesTransformer\n",
    "\n",
    "mol_from_smiles = MolFromSmilesTransformer(suppress_warnings=True)\n",
    "mols = mol_from_smiles.transform(df_out[\"SMILES\"].tolist())\n",
    "\n",
    "fpgen = ECFPFingerprint(count=False, radius=2, fp_fize=2048)\n",
    "fps = fpgen.transform(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfp.fingerprints import ECFPFingerprint\n",
    "from skfp.distances import tanimoto_binary_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6187e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of Tanimoto similarities to the reference set (ExpansionRx teaser)\n",
    "fpgen = ECFPFingerprint(count=False)\n",
    "fps = fpgen.transform(df_out[\"SMILES\"].tolist())\n",
    "\n",
    "# compute Tanimoto similarities to reference set\n",
    "fps_ref = fps[df_out[\"dataset\"] == \"expansionrx\"]\n",
    "for dataset_name, group in df_out.groupby(\"dataset\"):\n",
    "    if dataset_name == \"expansionrx\":\n",
    "        continue\n",
    "   \n",
    "    fps_group = fps[group.index.tolist()]\n",
    "    tanimoto_sims = np.zeros((len(fps_group), len(fps_ref)))\n",
    "    for i in range(len(fps_group)):\n",
    "        for j in range(len(fps_ref)):\n",
    "            tanimoto_sims[i, j] = fpgen.tanimoto(fps_group[i], fps_ref[j])\n",
    "    max_sims = tanimoto_sims.max(axis=1)\n",
    "    \n",
    "    # plot distribution of max Tanimoto similarities\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.kdeplot(\n",
    "        max_sims,\n",
    "        ax=ax,\n",
    "        fill=True,\n",
    "        alpha=0.5,\n",
    "        color=dataset_to_color[dataset_name],\n",
    "    )\n",
    "    ax.set_xlabel(\"Max Tanimoto Similarity to ExpansionRx Teaser\", fontsize=14)\n",
    "    ax.set_ylabel(\"Density\", fontsize=14)\n",
    "    ax.set_title(f\"Tanimoto Similarity Distribution for {dataset_name}\", fontsize=18)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=30, labelsize=12)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    fig.savefig(\n",
    "        output_dir / f\"combined_{dataset_name}_tanimoto_similarity_distribution.png\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e347401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: look at SMILES overlap between datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenADMET-ExpansionRx-Blind-Challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
